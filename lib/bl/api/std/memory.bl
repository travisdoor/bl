//! # Memory
//! 
//! ```
//! #load "std/memory.bl"
//! ```
//! 
//! Toolset for manipulation with the system memory.
//!
//! ## Memory allocator
//!
//! Memory allocators are used across the entire program to manage allocated memory resources used 
//! in runtime. Since memory allocation can be an expensive operation in some cases, it's good to 
//! provide an explicit API, giving information enough to fix bugs, memory leaks and performance
//! issues.
//!
//! Memory allocator in BL world is just some context [Allocator](#allocator) structure used by an
//! allocator [handler function](#allocfn).
//!
//! Functions like [alloc](#alloc) and [free](#free) internally use allocator set in global executable
//! context `application_context` variable. Global context allocator is by default set to `default_allocator`
//! and can be changed as needed.

#import "std/pool"

/// Default memory allocation alignment.
DEFAULT_ALIGNMENT : usize : alignof(f64);

/// Default memory allocator using libc malloc internally.
///
/// ### Supported Operation
/// 
///     - [x] Allocate
///     - [x] Reallocate
///     - [x] Free
///     - [ ] Release
///     - [ ] Reset
///
default_allocator :: Allocator.{ handler = &default_allocator_handler };

/// Default temporary allocator instance using pool internally (by default set into the application context).
///
/// The temporary allocator (used i.e. by [tprint](print.md#tprint) function) is useful in cases we
/// don't need to keep allocated memory for a long period of time. In general in such a case we allocate,
/// use and free the memory.
///
/// Temporary allocated memory does not need to be explicitly freed (in fact temporary allocator does not
/// free individual allocations at all even if `free` is called). A large memory block is preallocated instead
/// and every allocation lands into this block. Later (at some safe point of execution) when
/// [temporary_reset](#temporary_reset) is called, all previous allocations done via temporary allocator became
/// invalid (marked as a free space in preallocated block) and can be reused lated.
///
/// When temporary allocator is not needed anymore, [temporary_release](temporary_release) shall be called to
/// free all internally preallocated blocks.
///
/// Underlying allocator works with thread-local data storage (it's safe to use it in threads without any synchronization
/// required). But, when used from thread, each thread-local instance must be terminated by [temporary_release](#temporary_release)
/// call. In case you use `async` module the release is called automatically when internal threads exits.
///
/// ### Example
///
/// ```
/// main :: fn () s32 {
///     // Release allocated memory at the end of the scope.
///     defer temporary_release();
///
///     loop i := 0; i < 1000; i += 1 {
///          // Reset the allocator here (all previous alocation are invalid since now).
///         defer temporary_reset();
///
///         // Allocate memory using temporary allocator.
///         int_ptr := cast(*s32) alloc(sizeof(s32), alignof(s32), &default_temporary_allocator);
///
///         // Do something here with allocated memory.
///         @int_ptr = i;
///
///         // There is no need to free allocated memory here.
///     }
///     return 0;
/// }
/// ```
///
/// !!! note
///     The temporary allocator internally use [pool allocator](pool.md#pool_allocator), see the documentation for
///     more details.
default_temporary_allocator :: Allocator.{ handler = &temporary_allocator_handler };

/// Specify allocator opratation.
AllocOp :: enum {
	/// Allocation of new memory block is required.
	ALLOCATE;
	/// Reallocate previously allocated memory.
	REALLOCATE;
	/// Free of previously allocated memory. This operation is optional (i.e. for pools).
	FREE;
	/// Reset the allocated resources, but keep them for later use.
	RESET;
	/// Release all resources but keep the allocator instance in initialized state.
	RELEASE;
}

/// Allocator handle function type.
AllocFn :: *fn (
	ctx: *Allocator, // Current allocator context.
	operation: AllocOp, // Allocation operation.
	ptr: *u8, // Optional pointer to the previous allocation (in case of realloc).
	size: usize, // Allocation size in bytes.
	alignment: usize, // Allocation alignment.
	file: string_view, // Source file from where the allocation was done.
	line: s32 // Source line from where the allocation was done.
) (mem: *u8, err: Error);

/// Default allocator context base. This structure can be used as a base structure for any allocator
/// implementation.
Allocator :: struct {
	/// Pointer to the main allocator handler function.
	handler: AllocFn;
}

/// Allocate memory using specified `preferred_allocator`. In case the `preferred_allocator` is null, default application context
/// allocator is used.
///
/// Returns pointer to the newly allocated memory capable to handle `size` bytes, or fails with `Error` in case the 
/// allocation is not possible.
///
/// The allocation `size` must be at least 1 byte and the optional `alignment` must be value of power of two. Use `alignof`
/// helper function to resolve the best memory alignment for the required type.
alloc :: fn (size: usize, alignment := DEFAULT_ALIGNMENT, preferred_allocator: *Allocator = null, loc := #call_location) (mem: *u8, err: Error) #inline {
	allocator := preferred_allocator;
	if !allocator { allocator = application_context.allocator; }
	assert(allocator.handler);
	assert(is_power_of_two(alignment));
	if size == 0 { return null, error("Attempt to allocate 0 bytes."); }
	mem, err :: allocator.handler(allocator, AllocOp.ALLOCATE, null /* ptr */, size, alignment, loc.file, loc.line);
	if err { return mem, err; }
	assert(is_aligned(mem, alignment));
	return mem, err;
}

/// Reallocate previously allocated memory using the `preferred_allocator`. In case the `preferred_allocator` is null, 
/// default application context allocator is used.
///
/// Behavior depends on allocator being used. Usually when the previous allocation pointer `ptr` is specified, the 
/// implementation should try to resize already allocated block of memory to the requested `size`. In case resize is not 
/// possible, or is not supported by the allocator, new memory block is allocated to handle `size` of bytes, and data from the 
/// previous block are copied (memory area with size equal the lesser of the new and the old allocation sizes) into the newly 
/// allocated block. The previous allocated block is freed.
///
/// The allocation `size` must be at least 1 byte and the optional `alignment` must be value of power of two. Use `alignof`
/// helper function to resolve the best memory alignment for the required type.
///
/// In case the `ptr` is `null`, behavior is supposed to be the same as [alloc](#alloc).
realloc :: fn (ptr: *u8, size: usize, alignment := DEFAULT_ALIGNMENT, preferred_allocator: *Allocator = null, loc := #call_location) (mem: *u8, err: Error) #inline {
	allocator := preferred_allocator;
	if !allocator { allocator = application_context.allocator; }
	assert(allocator.handler);
	assert(is_power_of_two(alignment));
	if size == 0 { return null, error("Attempt to allocate 0 bytes."); }
	mem, err :: allocator.handler(allocator, AllocOp.REALLOCATE, ptr, size, alignment, loc.file, loc.line);
	if err { return mem, err; }
	assert(is_aligned(mem, alignment));
	return mem, err;
}

/// Allocates new object of type `T` on heap using `preferred_allocator`, in case the allocator is not specified, the current context
/// allocator is used.
///
/// Newly allocated memory block is zero initialized by default unless the `noinit` is `true`.
///
/// Use [free](#free) to release allocated memory when it's not needed anymore.
new :: fn (T: type #comptime, noinit := false, preferred_allocator: *Allocator = null, loc := #call_location) (ptr: *T, err: Error) #inline {
	mem, err :: alloc(sizeof(T), alignof(T), preferred_allocator, loc);
	if err { return auto mem, err; }
	if !noinit {
		zeromem(mem, sizeof(T));
	}
	return auto mem, OK; 
}

/// Allocates new slice of 'element_count' elements of 'TElement' type. 
///
/// Newly allocated memory block is zero initialized by default unless the `noinit` is `true`.
///
/// Use [free_slice](#free_slice) to release allocated memory when it's not needed anymore.
new_slice :: fn (TElement: type #comptime, element_count: s64, noinit := false, preferred_allocator: *Allocator = null, loc := #call_location) (slice: []TElement, err: Error) {
	assert(element_count >= 0, "Invalid element count!");
	slice: []TElement;
	if element_count == 0 { return slice, OK; }
	bytes :: sizeof(TElement) * cast(usize) element_count;
	mem, err :: alloc(bytes, alignof(TElement), preferred_allocator, loc);
	if err { return slice, err; }
	if !noinit {
		zeromem(mem, bytes);
	}
	slice.ptr = auto mem;
	slice.len = element_count;
	return slice, OK;
}

/// Free memory previously allocated by specific `preferred_allocator`. In case the `preferred_allocator` is null, 
/// the default application context allocator is used. The `ptr` can be null.
free :: fn (ptr: *u8, preferred_allocator: *Allocator = null, loc := #call_location) #inline {
	allocator := preferred_allocator;
	if !allocator { allocator = application_context.allocator; }
	assert(allocator.handler);
	if !ptr { return; }
	allocator.handler(allocator, AllocOp.FREE, ptr, 0 /* size */, 0 /* alignment */, loc.file, loc.line);
}

/// Release slice memory allocated by [alloc_slice](#alloc_slice) or [new_slice](#new_slice) call. The input slice is
/// set to the zero initialized state.
///
/// !!! warning
///     The `allocator` must match the allocator used by 'alloc_slice' or 'new_slice'.
free_slice :: fn (slice: *[]?T, allocator: *Allocator = null, loc := #call_location) {
	if slice.ptr {
		free(auto slice.ptr, allocator, loc);
		slice.ptr = null;
	}
	slice.len = 0;
}

/// Invoke the reset operation on the `allocator`. If supported, the `allocator` should reset its internal state (make
/// all allocation invalid) and reuse already allocated memory eventually for following allocations.
reset_allocator :: fn (allocator: *Allocator, loc := #call_location) #inline {
	assert(allocator.handler);
	allocator.handler(allocator, AllocOp.RESET, null, 0, 0, loc.file, loc.line);
}

/// Invoke the release operation on the `allocator`. If the operation is supported, the allocator should release all resources and free
/// all internally allocated memory. 
release_allocator :: fn (allocator: *Allocator, loc := #call_location) #inline {
	assert(allocator.handler);
	allocator.handler(allocator, AllocOp.RELEASE, null, 0, 0, loc.file, loc.line);
}

/// Copy memory of defined `size` from `source` to `destination`. Destination and source size must be at least
/// `size` bytes.
memcpy :: fn (destination: *u8, source: *u8, size: usize) {
	dest := destination;
	src  := source;

	m :: size / sizeof(u64);
	d :: size - m * sizeof(u64);
	loop i : usize = 0; i < m; i += 1 {
		tmp := cast(*u64) dest;
		@tmp = @cast(*u64) src;
		dest = ptr_shift_bytes(dest, auto sizeof(u64));
		src = ptr_shift_bytes(src, auto sizeof(u64));
	}
	loop i : usize = 0; i < d; i += 1 {
		@dest = @src;

		dest = ptr_shift_bytes(dest, 1);
		src = ptr_shift_bytes(src, 1);
	}
};

/// Set memory to desired value and return `destination` pointer. Destination size must be at least `size` bytes.
memset :: fn (destination: *u8, value: u8, size: usize) *u8 {
	dest := []u8.{auto size, destination};
	loop i := 0; i < dest.len; i += 1 {
		dest[i] = value;
	}
	return destination;
}

/// Copy 'size' bytes of data from memory location at 'source' to the 'destination' and returns 'destination'.
memmove :: fn (destination: *u8, source: *u8, size: usize) *u8 {
	_memmove :: fn (destination: *u8, source: *u8, size: usize, is_volatile: bool) #intrinsic "memmove.p0.p0.i64";
	_memmove(destination, source, size, false);
	return destination;
}

/// Zero out `destination` memory of `size` and return the original `destination` pointer. 
/// This function is internally optimized to zero the `destination` memory in 64 bit blocks if possible.
zeromem :: fn (destination: *u8, size: usize) *u8 {
	ptr := destination;
	m :: size / sizeof(u64);
	d :: size - m * sizeof(u64);
	loop i : usize = 0; i < m; i += 1 {
		tmp := cast(*u64) ptr;
		@tmp = 0;
		ptr = auto (cast(u64) ptr + sizeof(u64));
	}
	loop i : usize = 0; i < d; i += 1 {
		@ptr = 0;
		ptr = auto (cast(u64) ptr + 1);
	}
	return destination;
}

/// Zero initialize memory block at `ptr` and `sizeof(T)`. Returns passed `ptr` this might be useful in case of
/// "inline chaining".
///
/// ### Example
/// 
/// ```
/// foo :: zeroinit(array_push(&my_array));
/// ```
zeroinit :: fn (ptr: *?T) *T #inline {
	return auto zeromem(auto ptr, sizeof(T));
}

// Zero initialize slice memory.
zero_slice :: fn (slice: []?T) #inline {
	if slice.len == 0 { return; }
	zeromem(auto slice.ptr, sizeof(T) * auto slice.len);
}

/// Swaps content of memory at address `first` and `second`.
swap :: fn (first: *?T, second: *T) #inline {
	tmp :: @first;
	@first = @second;
	@second = tmp;
}

/// Checks whether passed pointer `ptr` is properly aligned by `alignment`.
is_aligned :: fn (ptr: *?T, alignment: usize) bool #inline {
	return cast(usize)ptr % alignment == 0;
}

/// Align pointer `p` to `alignment` and return adjusted pointer and number of bytes needed for 
/// adjustment.
///
/// !!! warning
///     Cause panic when alignment is not power of two.
align_ptr_up :: fn (p: *u8, alignment: usize) (p: *u8, adjustment: usize)
{
	if is_aligned(p, alignment) { return p, 0; }
	mask : usize : alignment - 1;
	assert((alignment & mask) == 0); // pwr of 2
	i_unaligned :: cast(usize)p;
	misalignment :: i_unaligned & mask;
	adj :: alignment - misalignment;
	return cast(*u8)(i_unaligned + adj), adj;
}

// @Incomplete: Slice allocs should return error and do not implicitly panic!

/// Allocate heap memory for `n` elements in the `slice`. Newly allocated slice can be zero initialized
/// by setting `zero_init` to `true`. Custom allocator can be provided as `allocator`, the application context
/// allocator is used in case the `allocator` is null.
///
/// Allocated memory must be released by [free_slice](#free_slice) call.
///
/// ### Example
/// 
/// ```
/// main :: fn () s32 {
///     // Allocate slice of 10 numbers
///     sl: []s32;
///     alloc_slice(&sl, 10);
/// 
///     loop i := 0; i < sl.len; i += 1 {
///         sl[i] = i;
///     }
/// 
///     // release memory allocated by init
///     free_slice(&sl);
///     return 0;
/// }
/// ```
///
/// !!! note
///     Zero initialization of allocated memory block can be expensive in case of large number of elements.
alloc_slice :: fn (slice: *[]?T, n: s64, zero_initialized := true, allocator: *Allocator = null, loc := #call_location) Error {
	if n < 0 { panic("Attempt to allocate % elements in slice!", n); }
	if n == 0  {
		slice.ptr = null;
		slice.len = 0;
		return OK;
	}
	elem_size :: sizeof(T);
	bytes :: elem_size * auto n;
	mem, err :: alloc(bytes, alignof(T), allocator, loc);
	if err { return err; }
	slice.ptr = auto mem;
	slice.len = n;
	if zero_initialized { zeromem(auto slice.ptr, bytes); }
	return OK;
}

/// Create slice subset defined as range `<start-index, end-index)`. Notice that `end` index
/// is excluded from range, so ``slice_range(other, 0, other.len)`` is valid and returns
/// new slice pointing to the same data as `other` slice, and with same size.
/// 
/// Indexing rules:
///
/// ```
/// start >= 0
/// start < slice.len
/// end >= 0
/// end <= slice.len
/// ```
///
/// !!! warning
///     Function cause panic in case combination of `start` and `end` is out of `slice` range.
slice_range :: fn (slice: []?T, start: s64, end: s64 = -1) []T #inline {
	e := end; 
	if e < 0 { e = slice.len; }
	len :: e - start;
	if len < 0 || len > slice.len || start < 0 || start >= slice.len {
		 panic("Invalid slice range, wanted <%, %) slice size is %.", start, end, slice.len);
	}
	return []T.{len, auto ptr_shift_bytes(slice.ptr, start * cast(s64) sizeof(T))};
}

/// Reduce allocated memory in application context temporary allocator storage, but keeps biggest allocated chunk for 
/// the later use.
///
/// !!! warning
///     All resources previously allocated by this allocator became invalid after reset.
///
/// !!! note
///     Call this method i.e. in every event loop (update) iteration.
temporary_reset :: fn () #inline {
	reset_allocator(application_context.temporary_allocator);
}

/// Release all memory allocated by the application context temporary allocator.
///
/// !!! warning
///     All resources previously allocated by this allocator became invalid after release.
///
/// !!! note
///     This method is implicitly called at exit of executable (after main).
temporary_release :: fn () #inline {
	release_allocator(application_context.temporary_allocator);
}

/// Produce right-shift of input `ptr` by count of `bytes`.
ptr_shift_bytes :: fn (ptr: *?T, bytes: s64) *T #inline {
	return auto (cast(s64) ptr + bytes);
};

/// Calculates pointer difference `a` - `b`.
ptr_diff :: fn (a: *?T1, b: *?T2) s64 #inline {
	return (cast(s64) a) - (cast(s64) b); 
}

#private
default_allocator_handler :: fn (
	allocator: *Allocator #maybe_unused,
	operation: AllocOp,
	ptr: *u8,
	size: usize,
	alignment: usize,
	file: string_view #maybe_unused,
	line: s32 #maybe_unused)
(mem: *u8, err: Error) {
	// @Cleanup: We do properly aligned allocations only on Windows, in case there is not implementation
	// provided on other platforms, we should implement it.
	alignment; // May be unused...
	using AllocOp;
	switch operation {
		ALLOCATE {
			mem: *u8;
#if PLATFORM == Platform.WINDOWS {
			mem = C.aligned_malloc(size, alignment);
} else {
			mem = C.malloc(size);
}
			if !mem { return null, error("Bad allocation."); }
			return mem, OK;
		}
		REALLOCATE {
			mem: *u8;
#if PLATFORM == Platform.WINDOWS {
			mem = C.aligned_realloc(ptr, size, alignment);
} else {
			mem = C.realloc(ptr, size);
}
			if !mem { return null, error("Bad reallocation."); }
			return mem, OK;
		}
		FREE {
#if PLATFORM == Platform.WINDOWS {
			C.aligned_free(ptr);
} else {
			C.free(ptr);
}
		}
		
		RESET, RELEASE {
			panic("Unsupported operation: %.", operation);
		}

		default { panic("Unknown operation."); }
	}
	return null, OK;
}

temporary_pool := std.pool_default #thread_local;

temporary_allocator_handler :: fn (
	_: *Allocator,
	operation: AllocOp,
	ptr: *u8,
	size: usize,
	alignment: usize,
	file: string_view,
	line: s32)
(mem: *u8, err: Error) #inline {
	return temporary_pool.handler(&temporary_pool, operation, ptr, size, alignment, file, line);
}
